{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71a1aef8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71a1aef8",
        "outputId": "1fc05269-c5e5-4ef9-9d4c-13ddcdc84c64"
      },
      "outputs": [],
      "source": [
        "# 1) Instalo los paquetes necesarios y los importo\n",
        "#%pip install --quiet torch torchvision tqdm pillow gradio sentence-transformers pytorch-fid accelerate\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from tqdm import tqdm\n",
        "\n",
        "print('PyTorch version:', torch.__version__)\n",
        "print('CUDA available:', torch.cuda.is_available())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d320eaa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "d320eaa4",
        "outputId": "6857c970-b366-4705-f788-52c17fdc337c"
      },
      "outputs": [],
      "source": [
        "# 2) Asigno directorios de las imagenes de entrenamiento, checkpoints y salidas\n",
        "\n",
        "BASE_DIR = r'c:\\Users\\Walter\\Desktop\\IA_GAN_labels_project'\n",
        "DATA_DIR = os.path.join(BASE_DIR, 'data/labels')\n",
        "CKPT_DIR = os.path.join(BASE_DIR, 'checkpoints')\n",
        "OUT_DIR = os.path.join(BASE_DIR, 'outputs')\n",
        "\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "print('BASE_DIR =', BASE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "631132d3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "631132d3",
        "outputId": "c71625a5-0b08-4c5f-996f-5ef96088454e"
      },
      "outputs": [],
      "source": [
        "# 3) Dataset y DataLoader \n",
        "IMG_SIZE = 128  \n",
        "BATCH_SIZE = 32\n",
        "z_dim = 128\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(IMG_SIZE),\n",
        "    transforms.CenterCrop(IMG_SIZE),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.2,0.2,0.2)], p=0.8),\n",
        "    transforms.RandomRotation(3),\n",
        "    transforms.RandomPerspective(distortion_scale=0.05, p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3)  \n",
        "])\n",
        "\n",
        "if not os.path.exists(DATA_DIR):\n",
        "    print(f\"[!] DATA_DIR not found: {DATA_DIR}. Please upload your dataset to Drive before running this cell.\")\n",
        "else:\n",
        "    dataset = datasets.ImageFolder(DATA_DIR, transform=transform)\n",
        "    dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True)\n",
        "    print('Dataset loaded. Classes:', dataset.classes)\n",
        "    print('Dataset size:', len(dataset))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca31026c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ca31026c",
        "outputId": "a7f752da-e944-4c96-b4af-8ed5c07dead6"
      },
      "outputs": [],
      "source": [
        "# 4) Modelos: Definici√≥n del Generador y Cr√≠tico (estilo WGAN-GP)\n",
        "import torch.nn as nn\n",
        "\n",
        "def conv_block(in_c, out_c, k=4, s=2, p=1, batchnorm=True):\n",
        "    layers = [nn.Conv2d(in_c, out_c, k, s, p, bias=False)]\n",
        "    if batchnorm:\n",
        "        layers.append(nn.BatchNorm2d(out_c))\n",
        "    layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class Critic(nn.Module):\n",
        "    def __init__(self, in_channels=3, base_feat=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # [3, 128, 128] ‚Üí [64, 64, 64]\n",
        "            nn.Conv2d(in_channels, base_feat, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # [64, 64, 64] ‚Üí [128, 32, 32]\n",
        "            nn.Conv2d(base_feat, base_feat*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(base_feat*2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # [128, 32, 32] ‚Üí [256, 16, 16]\n",
        "            nn.Conv2d(base_feat*2, base_feat*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(base_feat*4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # [256, 16, 16] ‚Üí [512, 8, 8]\n",
        "            nn.Conv2d(base_feat*4, base_feat*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(base_feat*8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # [512, 8, 8] ‚Üí [1, 1, 1]\n",
        "            nn.Conv2d(base_feat*8, 1, 8, 1, 0, bias=False)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.net(x)\n",
        "        return out.view(x.size(0))  \n",
        "\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=128, out_channels=3, base_feat=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(z_dim, base_feat*8, 4, 1, 0, bias=False),  \n",
        "            nn.BatchNorm2d(base_feat*8),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(base_feat*8, base_feat*4, 4, 2, 1, bias=False),  \n",
        "            nn.BatchNorm2d(base_feat*4),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(base_feat*4, base_feat*2, 4, 2, 1, bias=False),  \n",
        "            nn.BatchNorm2d(base_feat*2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(base_feat*2, base_feat, 4, 2, 1, bias=False),    \n",
        "            nn.BatchNorm2d(base_feat),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(base_feat, base_feat//2, 4, 2, 1, bias=False),   \n",
        "            nn.BatchNorm2d(base_feat//2),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(base_feat//2, out_channels, 4, 2, 1, bias=False),  \n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "\n",
        "# Verificaci√≥n r√°pida de la cantidad de par√°metros\n",
        "z_dim = 128\n",
        "gen = Generator(z_dim=z_dim)\n",
        "critic = Critic()\n",
        "print('Generator params:', sum(p.numel() for p in gen.parameters()))\n",
        "print('Critic params:', sum(p.numel() for p in critic.parameters()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "017de6db",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "017de6db",
        "outputId": "b2e9c54b-45af-41e7-b35f-dc0e12baa5b8"
      },
      "outputs": [],
      "source": [
        "# 5) Utilidades de entrenamiento y bucle de entrenamiento\n",
        "import torch.autograd as autograd\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "critic.to('cuda')\n",
        "gen.to('cuda')  \n",
        "\n",
        "\n",
        "def gradient_penalty(critic, real, fake, device):\n",
        "    bs = real.size(0)\n",
        "    eps = torch.rand(bs, 1, 1, 1, device=device)\n",
        "    inter = eps * real + (1 - eps) * fake\n",
        "    inter.requires_grad_(True)\n",
        "    out = critic(inter)\n",
        "    grad = torch.autograd.grad(outputs=out, inputs=inter,\n",
        "                               grad_outputs=torch.ones_like(out),\n",
        "                               create_graph=True, retain_graph=True, only_inputs=True)[0]\n",
        "    grad = grad.view(bs, -1)\n",
        "    gp = ((grad.norm(2, dim=1) - 1)**2).mean()\n",
        "    return gp\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def train_wgangp(gen, critic, dataloader, epochs=400, z_dim=128, device='cuda'):\n",
        "    gen.to(device); critic.to(device)\n",
        "    opt_g = optim.Adam(gen.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
        "    opt_c = optim.Adam(critic.parameters(), lr=1e-4, betas=(0.5, 0.9))\n",
        "    scaler_g = GradScaler(); scaler_c = GradScaler()\n",
        "    fixed_z = torch.randn(64, z_dim, 1, 1, device=device)\n",
        "\n",
        "    os.makedirs(CKPT_DIR, exist_ok=True); os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "    step = 0\n",
        "    for epoch in range(epochs):\n",
        "        pbar = tqdm(dataloader, desc=f'Epoch {epoch}')\n",
        "        for i, (real, _) in enumerate(pbar):\n",
        "            real = real.to(device)\n",
        "            bs = real.size(0)\n",
        "\n",
        "            \n",
        "            for _ in range(5):\n",
        "                z = torch.randn(bs, z_dim, 1, 1, device=device)\n",
        "                with autocast():\n",
        "                    fake = gen(z).detach()\n",
        "                    c_real = critic(real)\n",
        "                    c_fake = critic(fake)\n",
        "                    gp = gradient_penalty(critic, real, fake, device)\n",
        "                    loss_c = -(torch.mean(c_real) - torch.mean(c_fake)) + 10.0 * gp\n",
        "                opt_c.zero_grad(); scaler_c.scale(loss_c).backward(); scaler_c.step(opt_c); scaler_c.update()\n",
        "\n",
        "            \n",
        "            z = torch.randn(bs, z_dim, 1, 1, device=device)\n",
        "            with autocast():\n",
        "                fake = gen(z)\n",
        "                loss_g = -torch.mean(critic(fake))\n",
        "            opt_g.zero_grad(); scaler_g.scale(loss_g).backward(); scaler_g.step(opt_g); scaler_g.update()\n",
        "\n",
        "            if step % 200 == 0:\n",
        "                with torch.no_grad():\n",
        "                    fake_fixed = gen(fixed_z).detach().cpu()\n",
        "                    save_image(fake_fixed, os.path.join(OUT_DIR, f'fake_ep{epoch}_step{step}.png'), nrow=8, normalize=True)\n",
        "            step += 1\n",
        "\n",
        "        # checkpoint por epocas\n",
        "        torch.save({'gen': gen.state_dict(), 'critic': critic.state_dict()}, os.path.join(CKPT_DIR, f'ckpt_epoch_{epoch}.pt'))\n",
        "        print(f\"[Epoch {epoch}] checkpoint saved to {CKPT_DIR}\")\n",
        "\n",
        "\n",
        "train_wgangp(gen, critic, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79263c4b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "79263c4b",
        "outputId": "f2cc4ab9-e2da-4be9-904b-1c2b1c2b8d4f"
      },
      "outputs": [],
      "source": [
        "# 6) Mapeo de texto a espacio latente usando Sentence Transformers\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class TextToLatent(nn.Module):\n",
        "    def __init__(self, text_dim=384, z_dim=128):\n",
        "        super().__init__()\n",
        "        self.map = nn.Sequential(nn.Linear(text_dim, 256), nn.ReLU(), nn.Linear(256, z_dim))\n",
        "        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    def forward(self, text):\n",
        "        with torch.no_grad():\n",
        "            emb = self.encoder.encode([text], convert_to_tensor=True)\n",
        "        z = self.map(emb)\n",
        "        return z.unsqueeze(-1).unsqueeze(-1)\n",
        "\n",
        "mapper = TextToLatent(text_dim=384, z_dim=z_dim)\n",
        "print('Mapper created. Note: mapper is untrained; consider training with text-image pairs for better results.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d1ba892",
      "metadata": {
        "id": "0d1ba892"
      },
      "outputs": [],
      "source": [
        "# 7) Interfaz Gradio para texto->imagen\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "def load_generator(checkpoint_path, z_dim=128):\n",
        "    gen = Generator(z_dim=z_dim)\n",
        "    ckpt = torch.load(checkpoint_path, map_location='cpu')\n",
        "    gen.load_state_dict(ckpt['gen'])\n",
        "    return gen\n",
        "\n",
        "def generate_from_text(prompt, gen, mapper, n=4, device='cuda'):\n",
        "    gen.to(device); gen.eval()\n",
        "    mapper.to(device)\n",
        "    with torch.no_grad():\n",
        "        z = mapper(prompt).to(device)\n",
        "        z = z.repeat(n, 1, 1, 1)\n",
        "        imgs = gen(z)\n",
        "        imgs = (imgs + 1) / 2.0\n",
        "        grid = make_grid(imgs, nrow=2)\n",
        "        return grid.permute(1,2,0).cpu().numpy()\n",
        "\n",
        "\n",
        "def launch_gradio_interface(checkpoint_name='ckpt_epoch_111.pt'):\n",
        "    checkpoint_path = os.path.join(CKPT_DIR, checkpoint_name)\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        raise FileNotFoundError(f'Checkpoint not found: {checkpoint_path}. Train first or upload a checkpoint.')\n",
        "    gen = load_generator(checkpoint_path, z_dim=z_dim)\n",
        "    mapper = TextToLatent(text_dim=384, z_dim=z_dim)\n",
        "    iface = gr.Interface(fn=lambda prompt: generate_from_text(prompt, gen, mapper, n=4, device='cuda' if torch.cuda.is_available() else 'cpu'),\n",
        "                         inputs=gr.Textbox(lines=2, placeholder='Ej: etiqueta de vino elegante, fondo negro, tipograf√≠a dorada'),\n",
        "                         outputs=gr.Image(type='numpy'),\n",
        "                         title='Generador de etiquetas (GAN + Texto)',\n",
        "                         description='Describe la etiqueta que quer√©s generar. Usa t√©rminos visuales: colores, composici√≥n, estilo.')\n",
        "    iface.launch(share=True)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X9faZGbJg03o",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "X9faZGbJg03o",
        "outputId": "ec5c21c9-c659-4880-9015-fdf3b41ea5da"
      },
      "outputs": [],
      "source": [
        "launch_gradio_interface('ckpt_epoch_111.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6R1zF348qdRs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R1zF348qdRs",
        "outputId": "d827e054-2e1e-49e5-cb02-4922e616a0b7"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# üìä Evaluaci√≥n de la GAN - Curvas, FID, Ejemplos, Evaluaci√≥n Humana\n",
        "# ==========================================================\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid, save_image\n",
        "from torchvision import datasets, transforms\n",
        "from pytorch_fid import fid_score\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "# ==========================\n",
        "# 1. üìà Curvas de p√©rdida\n",
        "# ==========================\n",
        "def plot_losses(losses_g, losses_c, out_dir):\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.title(\"Curvas de p√©rdida - Generador vs Cr√≠tico\")\n",
        "    plt.plot(losses_g, label=\"Generator Loss\")\n",
        "    plt.plot(losses_c, label=\"Critic Loss\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(out_dir, \"training_losses.png\"))\n",
        "    plt.close()\n",
        "    print(\"‚úÖ Gr√°fico de p√©rdidas guardado en:\", out_dir)\n",
        "\n",
        "# ==========================\n",
        "# 2. üß© Muestras visuales por epoch\n",
        "# ==========================\n",
        "def save_sample_images(gen, fixed_z, epoch, out_dir):\n",
        "    gen.eval()\n",
        "    with torch.no_grad():\n",
        "        fake_images = gen(fixed_z).detach().cpu()\n",
        "    grid = make_grid(fake_images, nrow=8, normalize=True)\n",
        "    save_path = os.path.join(out_dir, f\"samples_epoch_{epoch}.png\")\n",
        "    save_image(grid, save_path)\n",
        "    print(f\"‚úÖ Imagen generada guardada: {save_path}\")\n",
        "    gen.train()\n",
        "\n",
        "# ==========================\n",
        "# 3. üìè FID Score (real vs generado)\n",
        "# ==========================\n",
        "def compute_fid(real_dir, fake_dir, device='cuda'):\n",
        "    fid_value = fid_score.calculate_fid_given_paths([real_dir, fake_dir],\n",
        "                                                    batch_size=32,\n",
        "                                                    device=device,\n",
        "                                                    dims=2048)\n",
        "    print(f\"‚úÖ FID Score: {fid_value:.2f}\")\n",
        "    return fid_value\n",
        "\n",
        "# ==========================\n",
        "# 4. üßç Evaluaci√≥n humana\n",
        "# ==========================\n",
        "def prepare_human_eval(fake_dir, n_samples=10, out_csv=\"human_eval_list.csv\"):\n",
        "    imgs = sorted([f for f in os.listdir(fake_dir) if f.endswith(\".png\")])\n",
        "    sample_imgs = imgs[:n_samples]\n",
        "    df = pd.DataFrame({\n",
        "        \"imagen\": sample_imgs,\n",
        "        \"plausibilidad(1-5)\": [\"\" for _ in range(n_samples)],\n",
        "        \"estetica(1-5)\": [\"\" for _ in range(n_samples)]\n",
        "    })\n",
        "    df.to_csv(os.path.join(fake_dir, out_csv), index=False)\n",
        "    print(f\"‚úÖ CSV generado para evaluaci√≥n humana: {out_csv}\")\n",
        "\n",
        "# ==========================\n",
        "# 5. üöÄ Ejemplo de uso\n",
        "# ==========================\n",
        "OUT_DIR = \"/content/drive/MyDrive/IA_GAN_labels_project/outputs\"\n",
        "CKPT_DIR = \"/content/drive/MyDrive/IA_GAN_labels_project/checkpoints\"\n",
        "REAL_DIR = \"/content/drive/MyDrive/IA_GAN_labels_project/data/labels/beer\"  # o wine / coffee\n",
        "\n",
        "# Cargar √∫ltimo checkpoint\n",
        "latest_ckpt = sorted(os.listdir(CKPT_DIR))[-1]\n",
        "ckpt_path = os.path.join(CKPT_DIR, latest_ckpt)\n",
        "checkpoint = torch.load(ckpt_path, map_location='cuda')\n",
        "gen.load_state_dict(checkpoint[\"gen\"])\n",
        "print(f\"‚úÖ Checkpoint cargado: {ckpt_path}\")\n",
        "\n",
        "# Generar muestras y graficar p√©rdidas (asume que guardaste las listas en el entrenamiento)\n",
        "fixed_z = torch.randn(64, 128, 1, 1, device='cuda')\n",
        "save_sample_images(gen, fixed_z, epoch=\"final\", out_dir=OUT_DIR)\n",
        "\n",
        "# Si guardaste losses durante el entrenamiento\n",
        "# plot_losses(losses_g, losses_c, OUT_DIR)\n",
        "\n",
        "# Calcular FID (usando real vs generado)\n",
        "FAKE_DIR = os.path.join(OUT_DIR, \"fid_fake_samples\")\n",
        "os.makedirs(FAKE_DIR, exist_ok=True)\n",
        "with torch.no_grad():\n",
        "    for i in range(100):\n",
        "        z = torch.randn(1, 128, 1, 1, device='cuda')\n",
        "        fake = gen(z).detach().cpu()\n",
        "        save_image(fake, os.path.join(FAKE_DIR, f\"fake_{i}.png\"), normalize=True)\n",
        "\n",
        "fid = compute_fid(REAL_DIR, FAKE_DIR)\n",
        "\n",
        "# Preparar CSV para evaluaci√≥n humana\n",
        "prepare_human_eval(FAKE_DIR, n_samples=10)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
