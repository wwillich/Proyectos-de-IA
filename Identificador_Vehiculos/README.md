# Proyecto: Identificador de Veh√≠culos con Transfer Learning

## Resumen del Proyecto
Este proyecto desarrolla un sistema de **Visi√≥n por Computadora** para la clasificaci√≥n de veh√≠culos en im√°genes. Se utiliz√≥ la arquitectura **Xception** a trav√©s de Transfer Learning y un pipeline implementado en Python, ejecutado desde R mediante la librer√≠a `reticulate`. El objetivo fue construir un detector de veh√≠culos funcional, ajustando librer√≠as (usando Keras3)  y aplicando t√©cnicas avanzadas de optimizaci√≥n para el entrenamiento.

## Stack Tecnol√≥gico

| Componente | Herramientas/Librer√≠as | Descripci√≥n |
| :--- | :--- | :--- |
| **Modelo Base** | Xception | Utilizado mediante Transfer Learning, con pesos congelados y entrenado con ImageNet. |
| **Frameworks** | Keras3, TensorFlow | Librer√≠as principales para la construcci√≥n y entrenamiento del modelo, elegidas para resolver problemas de compatibilidad. |
| **Lenguajes** | R, Python | El pipeline de entrenamiento y deployment fue ejecutado desde R usando Python a trav√©s de `reticulate`. |
| **Deployment** | Shiny | Utilizado para montar la interfaz gr√°fica del clasificador (`app.R`). |

## Procesamiento y Entrenamiento
El conjunto de datos utilizado fue ‚ÄúVehicle Image Classification‚Äù (Kaggle), complementado con im√°genes de camiones para ampliar el reconocimiento.

### 1. Preprocesamiento y Aumento de Datos
* **Aumento de Datos (*Data Augmentation*):** Se aplicaron volteos horizontales aleatorios y rotaciones leves (hasta el 10% del rango total). Esto expandi√≥ artificialmente el dataset, mejorando la robustez.
* **Normalizaci√≥n:** Los valores de p√≠xeles se reescalaron de $[0, 255]$ a $[0.0, 1.0]$ dividiendo por 255.
* **Prefetching:** Se implement√≥ para optimizar la entrada de datos, cargando lotes de im√°genes de forma as√≠ncrona.

### 2. Optimizaci√≥n y Control de Entrenamiento (Callbacks)
Para maximizar la eficiencia en 4 √©pocas  y evitar el sobreajuste (*overfitting*), se definieron dos mecanismos de control:

* **Early Stopping:** Monitoreando la P√©rdida de Validaci√≥n (`val_loss`). Se estableci√≥ una `patience = 3` y se us√≥ `restore_best_weights = TRUE` para asegurar que el modelo final fuese la mejor versi√≥n encontrada (la de menor `val_loss`).
* **Reduce Learning Rate On Plateau:** Si el rendimiento no mejora durante dos √©pocas (`patience = 2`), la **Tasa de Aprendizaje** se reduce autom√°ticamente al 50%. Esto permite que el optimizador encuentre el m√≠nimo error con mayor estabilidad y precisi√≥n.

### üìä Resultados del Modelo
* **M√©trica de Error:** Entrop√≠a Cruzada Categ√≥rica (`Categorical Crossentropy`).
* **Optimizador:** Adam.
* **M√©trica de Rendimiento:** Exactitud (`Accuracy`).

El entrenamiento se detuvo en la √âpoca 4 por las condiciones de *Early Stopping*.

| M√©trica | Conjunto de Entrenamiento (√âpoca 4) | Conjunto de Validaci√≥n (√âpoca 3 - Mejor Peso) |
| :--- | :--- | :--- |
| **Exactitud (Accuracy)** | 99% (M√°ximo en la √âpoca 4) | ~98.5% (M√°ximo en la √âpoca 3)  |
| **P√©rdida (Cross-Entropy)** | ~0.04 (M√≠nimo en la √âpoca 4) | ~0.06 (M√≠nimo en la √âpoca 3)  |

##Aprendizajes Clave
Este proyecto fue fundamental para comprender y aplicar estrategias avanzadas de entrenamiento y manejo de dependencias.
* **Gesti√≥n de Dependencias y Compatibilidad:** Se resolvi√≥ la incompatibilidad entre la versi√≥n de R y las librer√≠as Keras/TensorFlow al investigar y optar por **Keras3**.
* **Optimizaci√≥n del Entrenamiento:** El uso de **Early Stopping** y **Reduce Learning Rate On Plateau** permiti√≥ ajustar de manera √≥ptima y robusta la cantidad de √©pocas, ahorrando tiempo y evitando el sobreajuste (*overfitting*).
